
Greenplum相关计算


膨胀率：  dead_tuple/(dead_tuple+live_tuple) 数据取自表**pg_stat_all_tables**

统计差值率：(reltuples-live_tuples)/live_tuples  取自表**pg_class**

数据倾斜率：最大节点数据量/平均节点数据量

压缩率：压缩后数据量/压缩前数据量



#### GP5.0.0的一个BUG

**pg_stat_all_tables**定义按照PG的，对于某些指标没有在**master**节点汇总

例如下面的表删除行后产生的n_dead_tup 、n_live_tup 不准确。

原始定义：

postgres=# \d+ pg_stat_all_tables
                      View "pg_catalog.pg_stat_all_tables"
      Column      |           Type           | Modifiers | Storage | Description
------------------+--------------------------+-----------+---------+-------------
 relid            | oid                      |           | plain   |
 schemaname       | name                     |           | plain   |
 relname          | name                     |           | plain   |
 seq_scan         | bigint                   |           | plain   |
 seq_tup_read     | bigint                   |           | plain   |
 idx_scan         | bigint                   |           | plain   |
 idx_tup_fetch    | bigint                   |           | plain   |
 n_tup_ins        | bigint                   |           | plain   |
 n_tup_upd        | bigint                   |           | plain   |
 n_tup_del        | bigint                   |           | plain   |
 n_tup_hot_upd    | bigint                   |           | plain   |
 n_live_tup       | bigint                   |           | plain   |
 n_dead_tup       | bigint                   |           | plain   |
 last_vacuum      | timestamp with time zone |           | plain   |
 last_autovacuum  | timestamp with time zone |           | plain   |
 last_analyze     | timestamp with time zone |           | plain   |
 last_autoanalyze | timestamp with time zone |           | plain   |
View definition:
 SELECT c.oid AS relid, n.nspname AS schemaname, c.relname, pg_stat_get_numscans(c.oid) AS seq_scan, pg_stat_get_tuples_returned(c.
oid) AS seq_tup_read, sum(pg_stat_get_numscans(i.indexrelid))::bigint AS idx_scan, sum(pg_stat_get_tuples_fetched(i.indexrelid))::b
igint + pg_stat_get_tuples_fetched(c.oid) AS idx_tup_fetch, pg_stat_get_tuples_inserted(c.oid) AS n_tup_ins, pg_stat_get_tuples_upd
ated(c.oid) AS n_tup_upd, pg_stat_get_tuples_deleted(c.oid) AS n_tup_del, pg_stat_get_tuples_hot_updated(c.oid) AS n_tup_hot_upd, p
g_stat_get_live_tuples(c.oid) AS n_live_tup, pg_stat_get_dead_tuples(c.oid) AS n_dead_tup, pg_stat_get_last_vacuum_time(c.oid) AS l
ast_vacuum, pg_stat_get_last_autovacuum_time(c.oid) AS last_autovacuum, pg_stat_get_last_analyze_time(c.oid) AS last_analyze, pg_st
at_get_last_autoanalyze_time(c.oid) AS last_autoanalyze
   FROM pg_class c
   LEFT JOIN pg_index i ON c.oid = i.indrelid
   LEFT JOIN pg_namespace n ON n.oid = c.relnamespace
  WHERE c.relkind = ANY (ARRAY['r'::"char", 't'::"char"])
  GROUP BY c.oid, n.nspname, c.relname;

#### master提交查询：

postgres=# select * from pg_stat_all_tables where relname='test';
-[ RECORD 1 ]----+-------
relid            | 25557
schemaname       | public
relname          | test
seq_scan         | 0
seq_tup_read     | 0
idx_scan         |
idx_tup_fetch    |
n_tup_ins        | 0
n_tup_upd        | 0
n_tup_del        | 0
n_tup_hot_upd    | 0
n_live_tup       | 0
n_dead_tup       | 0
last_vacuum      |
last_autovacuum  |
last_analyze     |
last_autoanalyze |

#### segment查看：

postgres=# select relname,n_live_tup,n_dead_tup from gp_dist_random('pg_stat_all_tables') where relname='test';
-[ RECORD 1 ]----
relname    | test
n_live_tup | 4950
n_dead_tup | 49
-[ RECORD 2 ]----
relname    | test
n_live_tup | 4951
n_dead_tup | 50

## 规避办法

sql层面解决：

postgres=# select sum(n_live_tup) as n_live_tup ,sum(n_dead_tup) as n_dead_tup from gp_dist_random('pg_stat_all_tables') where relname='test';
-[ RECORD 1 ]----
n_live_tup | 9901
n_dead_tup | 99

源码层面来解决，改函数pg_stat_get_live_tuples、pg_stat_get_dead_tuples定义。

```
`Datum` `pg_stat_get_live_tuples(PG_FUNCTION_ARGS)`
`{`
​    `Oid         relid = PG_GETARG_OID(0);`
​    `int64       result;`
​    `PgStat_StatTabEntry *tabentry;`
​    `if ((tabentry = pgstat_fetch_stat_tabentry(relid)) == NULL)`
​        `result = 0;`
​    `else`
​        `result = (int64) (tabentry->n_live_tuples);`
	if (Gp_role == GP_ROLE_DISPATCH)
   {
     sql = psprintf("select n_live_tup from pg_stat_all_tables where relname(%u)", relid);
     result += get_size_from_segDBs(sql);
   }
​    `PG_RETURN_INT64(result);`
`}`

`Datum` `pg_stat_get_dead_tuples(PG_FUNCTION_ARGS)`
`{`
​    `Oid         relid = PG_GETARG_OID(0);`
​    `int64       result;`
​    `PgStat_StatTabEntry *tabentry;`
​    `if ((tabentry = pgstat_fetch_stat_tabentry(relid)) == NULL)`
​        `result = 0;`
​    `else`
​        `result = (int64) (tabentry->n_dead_tup);`
	if (Gp_role == GP_ROLE_DISPATCH)
   {
     sql = psprintf("select n_dead_tup from pg_stat_all_tables where relname(%u)", relid);
     result += get_size_from_segDBs(sql);
   }
​    `PG_RETURN_INT64(result);`
`}`
```

GP6.0定义

postgres=# \d+ pg_stat_all_tables
                        View "pg_catalog.pg_stat_all_tables"
       Column        |           Type           | Modifiers | Storage | Description
---------------------+--------------------------+-----------+---------+-------------
 relid               | oid                      |           | plain   |
 schemaname          | name                     |           | plain   |
 relname             | name                     |           | plain   |
 seq_scan            | bigint                   |           | plain   |
 seq_tup_read        | bigint                   |           | plain   |
 idx_scan            | bigint                   |           | plain   |
 idx_tup_fetch       | bigint                   |           | plain   |
 n_tup_ins           | bigint                   |           | plain   |
 n_tup_upd           | bigint                   |           | plain   |
 n_tup_del           | bigint                   |           | plain   |
 n_tup_hot_upd       | bigint                   |           | plain   |
 n_live_tup          | bigint                   |           | plain   |
 n_dead_tup          | bigint                   |           | plain   |
 n_mod_since_analyze | bigint                   |           | plain   |
 last_vacuum         | timestamp with time zone |           | plain   |
 last_autovacuum     | timestamp with time zone |           | plain   |
 last_analyze        | timestamp with time zone |           | plain   |
 last_autoanalyze    | timestamp with time zone |           | plain   |
 vacuum_count        | bigint                   |           | plain   |
 autovacuum_count    | bigint                   |           | plain   |
 analyze_count       | bigint                   |           | plain   |
 autoanalyze_count   | bigint                   |           | plain   |
View definition:
 SELECT c.oid AS relid,
    n.nspname AS schemaname,
    c.relname,
    pg_stat_get_numscans(c.oid) AS seq_scan,
    pg_stat_get_tuples_returned(c.oid) AS seq_tup_read,
    sum(pg_stat_get_numscans(i.indexrelid))::bigint AS idx_scan,
    sum(pg_stat_get_tuples_fetched(i.indexrelid))::bigint + pg_stat_get_tuples_fetched(c.oid) AS idx_tup_fetch,
    pg_stat_get_tuples_inserted(c.oid) AS n_tup_ins,
    pg_stat_get_tuples_updated(c.oid) AS n_tup_upd,
    pg_stat_get_tuples_deleted(c.oid) AS n_tup_del,
    pg_stat_get_tuples_hot_updated(c.oid) AS n_tup_hot_upd,
    pg_stat_get_live_tuples(c.oid) AS n_live_tup,
    pg_stat_get_dead_tuples(c.oid) AS n_dead_tup,
    pg_stat_get_mod_since_analyze(c.oid) AS n_mod_since_analyze,
    pg_stat_get_last_vacuum_time(c.oid) AS last_vacuum,
    pg_stat_get_last_autovacuum_time(c.oid) AS last_autovacuum,
    pg_stat_get_last_analyze_time(c.oid) AS last_analyze,
    pg_stat_get_last_autoanalyze_time(c.oid) AS last_autoanalyze,
    pg_stat_get_vacuum_count(c.oid) AS vacuum_count,
    pg_stat_get_autovacuum_count(c.oid) AS autovacuum_count,
    pg_stat_get_analyze_count(c.oid) AS analyze_count,
    pg_stat_get_autoanalyze_count(c.oid) AS autoanalyze_count
   FROM pg_class c
     LEFT JOIN pg_index i ON c.oid = i.indrelid
     LEFT JOIN pg_namespace n ON n.oid = c.relnamespace
  WHERE c.relkind = ANY (ARRAY['r'::"char", 't'::"char", 'm'::"char"])
  GROUP BY c.oid, n.nspname, c.relname;



## pg_database_size函数源码分析

计算指定oid的数据库的大小。

```
Datum pg_database_size_oid(PG_FUNCTION_ARGS)
{
​    Oid         dbOid = PG_GETARG_OID(0);
​    int64       size;
​    size = calculate_database_size(dbOid);
​    if (Gp_role == GP_ROLE_DISPATCH)
​    {
​        char       *sql;
​        sql = psprintf("select pg_catalog.pg_database_size(%u)", dbOid);
​        size += get_size_from_segDBs(sql);
​    }
​    if (size == 0)
​        PG_RETURN_NULL();
​    PG_RETURN_INT64(size);
}
```

/*

 \* calculate size of database in all tablespaces

计算所有表空间下的特定数据库大小

 */

```
`static int64` `calculate_database_size(Oid dbOid)`
`{`
​    `int64       totalsize;`
​    `DIR        *dirdesc;`
​    `struct dirent *direntry;`
​    `char        dirpath[MAXPGPATH];`
​    `char        pathname[MAXPGPATH + 12 + strlen(tablespace_version_directory()) + 1];`
​    `AclResult   aclresult;`
​    `/* User must have connect privilege for target database */`
​    `aclresult = pg_database_aclcheck(dbOid, GetUserId(), ACL_CONNECT);`
​    `if (aclresult != ACLCHECK_OK)`
​        `aclcheck_error(aclresult, ACL_KIND_DATABASE,`
​                       `get_database_name(dbOid));`
​    `/* Shared storage in pg_global is not counted */`
​    `/* Include pg_default storage */`
​    `snprintf(pathname, sizeof(pathname), "base/%u", dbOid);`
​    `totalsize = db_dir_size(pathname);`
```

```
/* Scan the non-default tablespaces */
​    snprintf(dirpath, MAXPGPATH, "pg_tblspc");
​    dirdesc = AllocateDir(dirpath);
​    if (!dirdesc)
​        ereport(ERROR,
​                (errcode_for_file_access(),
​                 errmsg("could not open tablespace directory \"%s\": %m",
​                        dirpath)));
​    while ((direntry = ReadDir(dirdesc, dirpath)) != NULL)
​    {
​        CHECK_FOR_INTERRUPTS();
​        if (strcmp(direntry->d_name, ".") == 0 ||
​            strcmp(direntry->d_name, "..") == 0)
​            continue;
​        snprintf(pathname, sizeof(pathname), "pg_tblspc/%s/%s/%u",
​                 direntry->d_name, tablespace_version_directory(), dbOid);
​        totalsize += db_dir_size(pathname);
​    }
​    FreeDir(dirdesc);
​    return totalsize;
}
```

/*

 \* Helper function to dispatch a size-returning command.

 * \* Dispatches the given SQL query to segments, and sums up the results.

 \* The query is expected to return one int8 value.

下发返回大小相关的命令到segment，并对结果求和，返回值为int8

 */

```
int64 get_size_from_segDBs(const char *cmd)
{
​    int64       result;
​    CdbPgResults cdb_pgresults = {NULL, 0};
​    int         i;
​    Assert(Gp_role == GP_ROLE_DISPATCH);
​    CdbDispatchCommand(cmd, DF_WITH_SNAPSHOT, &cdb_pgresults);
​    result = 0;
​    for (i = 0; i < cdb_pgresults.numResults; i++)
​    {
​        Datum       value;
​        struct pg_result *pgresult = cdb_pgresults.pg_results[i];
​        if (PQresultStatus(pgresult) != PGRES_TUPLES_OK)
​        {
​            cdbdisp_clearCdbPgResults(&cdb_pgresults);
​            ereport(ERROR,
​                    (errmsg("unexpected result from segment: %d",
​                            PQresultStatus(pgresult))));
​        }
​        if (PQntuples(pgresult) != 1 || PQnfields(pgresult) != 1)
​        {
​            cdbdisp_clearCdbPgResults(&cdb_pgresults);
​            ereport(ERROR,
​                    (errmsg("unexpected shape of result from segment (%d rows, %d cols)",
​                            PQntuples(pgresult), PQnfields(pgresult))));
​        }
​        if (PQgetisnull(pgresult, 0, 0))
​            value = 0;
​        else
​            value = DirectFunctionCall1(int8in,
​                                        CStringGetDatum(PQgetvalue(pgresult, 0, 0)));
​        result += value;
​    }
​    cdbdisp_clearCdbPgResults(&cdb_pgresults);
​    return result;
}
```
